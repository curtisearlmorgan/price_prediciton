{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of time_series.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb","timestamp":1577551110311}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"7rZnJaGTWQw0","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xyv_i85IWInT","colab":{}},"source":["zip_path = tf.keras.utils.get_file(\n","    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n","    fname='jena_climate_2009_2016.csv.zip',\n","    extract=True)\n","csv_path, _ = os.path.splitext(zip_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TX6uGeeeWIkG","colab":{}},"source":["df = pd.read_csv('/content/GOOG.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ojHE-iCCWIhz","colab":{}},"source":["df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7AoxQuTrWIbi","colab":{}},"source":["def univariate_data(dataset, start_index, end_index, history_size, target_size):\n","  data = []\n","  labels = []\n","\n","  start_index = start_index + history_size\n","  if end_index is None:\n","    end_index = len(dataset) - target_size\n","\n","  for i in range(start_index, end_index):\n","    indices = range(i-history_size, i)\n","    # Reshape data from (history_size,) to (history_size, 1)\n","    data.append(np.reshape(dataset[indices], (history_size, 1)))\n","    labels.append(dataset[i+target_size])\n","  return np.array(data), np.array(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ia-MPAHxbInX","colab":{}},"source":["TRAIN_SPLIT = 300000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-x-GgENynHdx","colab":{}},"source":["tf.random.set_seed(13)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nbdcnm1_WIY9","colab":{}},"source":["# uni_data = df['T (degC)']\n","# uni_data.index = df['Date Time']\n","# uni_data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ftOExwAqWXSU","colab":{}},"source":["# uni_data.plot(subplots=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ejSEiDqBWXQa","colab":{}},"source":["#uni_data = uni_data.values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Eji6njXvHusN","colab":{}},"source":["uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\n","uni_train_std = uni_data[:TRAIN_SPLIT].std()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BO55yRD6H0Dx","colab":{}},"source":["uni_data = (uni_data-uni_train_mean)/uni_train_std"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qVukM9dRipop","colab":{}},"source":["def create_time_steps(length):\n","  return list(range(-length, 0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QQeGvh7cWXMR","colab":{}},"source":["def show_plot(plot_data, delta, title):\n","  labels = ['History', 'True Future', 'Model Prediction']\n","  marker = ['.-', 'rx', 'go']\n","  time_steps = create_time_steps(plot_data[0].shape[0])\n","  if delta:\n","    future = delta\n","  else:\n","    future = 0\n","\n","  plt.title(title)\n","  for i, x in enumerate(plot_data):\n","    if i:\n","      plt.plot(future, plot_data[i], marker[i], markersize=10,\n","               label=labels[i])\n","    else:\n","      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n","  plt.legend()\n","  plt.xlim([time_steps[0], (future+5)*2])\n","  plt.xlabel('Time-Step')\n","  return plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pd05iV-UWXKL","colab":{}},"source":["show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P9nYWcxMMWnr","colab":{}},"source":["def baseline(history):\n","  return np.mean(history)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KMcdFYKQMWlm","colab":{}},"source":["show_plot([x_train_uni[0], y_train_uni[0], baseline(x_train_uni[0])], 0,\n","           'Baseline Prediction Example')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"067m6t8cMakb"},"source":["Let's see if you can beat this baseline using a recurrent neural network."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kk-evkrmMWh9","colab":{}},"source":["BATCH_SIZE = 256\n","BUFFER_SIZE = 10000\n","\n","train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n","train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n","\n","val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n","val_univariate = val_univariate.batch(BATCH_SIZE).repeat()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IDbpHosCMWZO","colab":{}},"source":["simple_lstm_model = tf.keras.models.Sequential([\n","    tf.keras.layers.LSTM(8, input_shape=x_train_uni.shape[-2:]),\n","    tf.keras.layers.Dense(1)\n","])\n","\n","simple_lstm_model.compile(optimizer='adam', loss='mae')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2mPZbIKCMtLR","colab":{}},"source":["for x, y in val_univariate.take(1):\n","    print(simple_lstm_model.predict(x).shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0opH9xi5MtIk","colab":{}},"source":["EVALUATION_INTERVAL = 200\n","EPOCHS = 10\n","\n","simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n","                      steps_per_epoch=EVALUATION_INTERVAL,\n","                      validation_data=val_univariate, validation_steps=50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DphrB7bxSNDd","colab":{}},"source":["features_considered = ['p (mbar)', 'T (degC)', 'rho (g/m**3)']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IfQUSiJfUpXJ","colab":{}},"source":["features = df[features_considered]\n","features.index = df['Date Time']\n","features.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QdgC8zvGr21X","colab":{}},"source":["features.plot(subplots=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W7VuNIwfHRHx","colab":{}},"source":["dataset = features.values\n","data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n","data_std = dataset[:TRAIN_SPLIT].std(axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eJUeWDqploCt","colab":{}},"source":["dataset = (dataset-data_mean)/data_std"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d-rVX4d3OF86","colab":{}},"source":["def multivariate_data(dataset, target, start_index, end_index, history_size,\n","                      target_size, step, single_step=False):\n","  data = []\n","  labels = []\n","\n","  start_index = start_index + history_size\n","  if end_index is None:\n","    end_index = len(dataset) - target_size\n","\n","  for i in range(start_index, end_index):\n","    indices = range(i-history_size, i, step)\n","    data.append(dataset[indices])\n","\n","    if single_step:\n","      labels.append(target[i+target_size])\n","    else:\n","      labels.append(target[i:i+target_size])\n","\n","  return np.array(data), np.array(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HlhVGzPhmMYI","colab":{}},"source":["past_history = 720\n","future_target = 72\n","STEP = 6\n","\n","x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 1], 0,\n","                                                   TRAIN_SPLIT, past_history,\n","                                                   future_target, STEP,\n","                                                   single_step=True)\n","x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 1],\n","                                               TRAIN_SPLIT, None, past_history,\n","                                               future_target, STEP,\n","                                               single_step=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-ZAdeAnP5c72","colab":{}},"source":["def plot_train_history(history, title):\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  epochs = range(len(loss))\n","\n","  plt.figure()\n","\n","  plt.plot(epochs, loss, 'b', label='Training loss')\n","  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","  plt.title(title)\n","  plt.legend()\n","\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2GnE087bJYSu"},"source":["### Multi-Step model\n","In a multi-step prediction model, given a past history, the model needs to learn to predict a range of future values. Thus, unlike a single step model, where only a single future point is predicted, a multi-step model predict a sequence of the future.\n","\n","For the multi-step model, the training data again consists of recordings over the past five days sampled every hour. However, here, the model needs to learn to predict the temperature for the next 12 hours. Since an obversation is taken every 10 minutes, the output is 72 predictions. For this task, the dataset needs to be prepared accordingly, thus the first step is just to create it again, but with a different target window."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kZCk9fqyJZqX","colab":{}},"source":["future_target = 72\n","x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, 1], 0,\n","                                                 TRAIN_SPLIT, past_history,\n","                                                 future_target, STEP)\n","x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, 1],\n","                                             TRAIN_SPLIT, None, past_history,\n","                                             future_target, STEP)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LImXPwAGRtWy"},"source":["Let's check out a sample data-point."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SpWDcBkQRwS-","colab":{}},"source":["print ('Single window of past history : {}'.format(x_train_multi[0].shape))\n","print ('\\n Target temperature to predict : {}'.format(y_train_multi[0].shape))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cjR4PJArMOpA","colab":{}},"source":["train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n","train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n","\n","val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n","val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IZcg8FWpSG8K"},"source":["Plotting a sample data-point."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ksXKVbwBV7D3","colab":{}},"source":["def multi_step_plot(history, true_future, prediction):\n","  plt.figure(figsize=(12, 6))\n","  num_in = create_time_steps(len(history))\n","  num_out = len(true_future)\n","\n","  plt.plot(num_in, np.array(history[:, 1]), label='History')\n","  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n","           label='True Future')\n","  if prediction.any():\n","    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n","             label='Predicted Future')\n","  plt.legend(loc='upper left')\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LCQKetflZRMF"},"source":["In this plot and subsequent similar plots, the history and the future data are sampled every hour."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R6G8bacQR4w2","colab":{}},"source":["for x, y in train_data_multi.take(1):\n","  multi_step_plot(x[0], y[0], np.array([0]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XOjz8DzZ4HFS"},"source":["Since the task here is a bit more complicated than the previous task, the model now consists of two LSTM layers. Finally, since 72 predictions are made, the dense layer outputs 72 predictions."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"byAl0NKSNBP6","colab":{}},"source":["multi_step_model = tf.keras.models.Sequential()\n","multi_step_model.add(tf.keras.layers.LSTM(32,\n","                                          return_sequences=True,\n","                                          input_shape=x_train_multi.shape[-2:]))\n","multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n","multi_step_model.add(tf.keras.layers.Dense(72))\n","\n","multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UvB7zBqVSMyl"},"source":["Let's see how the model predicts before it trains."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"13_ZWvB9SRlZ","colab":{}},"source":["for x, y in val_data_multi.take(1):\n","  print (multi_step_model.predict(x).shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7uwOhXo3Oems","colab":{}},"source":["multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n","                                          steps_per_epoch=EVALUATION_INTERVAL,\n","                                          validation_data=val_data_multi,\n","                                          validation_steps=50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UKfQoBjQ5l7U","colab":{}},"source":["plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oDg94-yq4pas"},"source":["#### Predict a multi-step future\n","Let's now have a look at how well your network has learnt to predict the future."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dt22wq6fyIBU","colab":{}},"source":["for x, y in val_data_multi.take(3):\n","  multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pOzaIRYBhqwg"},"source":["## Next steps\n","This tutorial was a quick introduction to time series forecasting using an RNN. You may now try to predict the stock market and become a billionaire.\n","\n","In addition, you may also write a generator to yield data (instead of the uni/multivariate_data function), which would be more memory efficient. You may also check out this [time series windowing](https://www.tensorflow.org/guide/data#time_series_windowing) guide and use it in this tutorial.\n","\n","For further understanding, you may read Chapter 15 of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/), 2nd Edition and Chapter 6 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)."]}]}